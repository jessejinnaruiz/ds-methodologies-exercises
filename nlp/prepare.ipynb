{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taco/Documents/Coding/Codeup/CourseWork/ds-methodologies-exercises/nlp/acquisition.py:41: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 41 of the file /Users/taco/Documents/Coding/Codeup/CourseWork/ds-methodologies-exercises/nlp/acquisition.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n",
      "/Users/taco/Documents/Coding/Codeup/CourseWork/ds-methodologies-exercises/nlp/acquisition.py:132: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 132 of the file /Users/taco/Documents/Coding/Codeup/CourseWork/ds-methodologies-exercises/nlp/acquisition.py. To get rid of this warning, pass the additional argument 'features=\"lxml\"' to the BeautifulSoup constructor.\n",
      "\n",
      "  soup = BeautifulSoup(response.text)\n"
     ]
    }
   ],
   "source": [
    "import unicodedata\n",
    "import re\n",
    "import json\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "import acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python -c \n",
    "# import nltk; nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'title': 'codeups-data-science-career-accelerator-is-here', 'contents': 'The rumors are true! The time has arrived. Codeup has officially opened applications to our new Data Science career accelerator, with only 25 seats available! This immersive program is one of a kind in San Antonio, and will help you land a job in\\xa0Glassdoor’s #1 Best Job in America.\\nData Science is a method of providing actionable intelligence from data.\\xa0The data revolution has hit San Antonio,\\xa0resulting in an explosion in Data Scientist positions\\xa0across companies like USAA, Accenture, Booz Allen Hamilton, and HEB. We’ve even seen\\xa0UTSA invest $70 M for a Cybersecurity Center and School of Data Science.\\xa0We built a program to specifically meet the growing demands of this industry.\\nOur program will be 18 weeks long, full-time, hands-on, and project-based. Our curriculum development and instruction is led by Senior Data Scientist, Maggie Giust, who has worked at HEB, Capital Group, and Rackspace, along with input from dozens of practitioners and hiring partners. Students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. They will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nWe focus on applied data science for immediate impact and ROI in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing Web Dev program. We’re focusing on Data Science with Python, SQL, and ML, covered in\\xa014 modules: 1) Fundamentals; 2) Applied statistics; 3) SQL; 4) Python; 5) Supervised machine learning – regression; 6) Supervised machine learning – classification; 7) Unsupervised machine learning – clustering; 8) Time series analysis; 9) Anomaly detection; 10) Natural language processing; 11) Distributed machine learning; 12) Advanced topics (deep learning, NoSQL, cloud deployment, etc.); 13) Storytelling with data; and 14) Domain expertise development.\\nApplications are now open\\xa0for Codeup’s first Data Science cohort, which will start class on February 4, 2019. Hurry – there are only 25 seats available! To further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, LGBTQIA+ individuals, veterans, first responders, and people relocating to San Antonio.\\nIf you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!', 'url': 'https://codeup.com/codeups-data-science-career-accelerator-is-here/'}, {'title': 'data-science-myths', 'contents': 'By Dimitri Antoniou and Maggie Giust\\nData Science, Big Data, Machine Learning, NLP, Neural Networks…these buzzwords have rapidly spread into mainstream use over the last few years. Unfortunately, definitions are varied and sources of truth are limited. Data Scientists are in fact not magical unicorn wizards who can snap their fingers and turn a business around! Today, we’ll take a cue from our favorite Mythbusters to tackle some common myths and misconceptions in the field of Data Science.\\n\\nvia GIPHY\\nMyth #1: Data Science = Statistics\\nAt first glance, this one doesn’t sound unreasonable. Statistics is defined as, “A branch of mathematics dealing with the collection, analysis, interpretation, and presentation of masses of numerical data.” That sounds a lot like our definition of Data Science: a method of drawing actionable intelligence from data. \\nIn truth, statistics is actually one small piece of Data Science. As our Senior Data Scientist puts it, “Statistics forces us to make assumptions about the nature of the relationship between variables, the distribution of the data, etc.” In the traditional Data Science venn diagram, you’ll see that math/stats make up ⅓ of a working professional. These are tools and skills to leverage, but data science itself is about drawing intelligence from data.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #2: Data Scientist = Business/Data Analyst\\nThis one is so common that we wrote a whole post about it! These are separate and different roles within the data field. While a data scientist will often do analytics, their spectrum of work is wider. A data analyst will use structured data to create dashboards and KPIs, while a Data Scientist deals with unstructured and messy data for a range of outputs. If they’re interested, business analysts will often progress to data scientists.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #3: Data Science = Data Science\\nThis one’s tricky, because it’s impossible to either confirm or bust! The ‘myth’ is that one person or company using the term Data Science is not necessarily the same as another person or company using the same term. Depending on organizational capacity, individual experience, educational background, and many other variables, we might be using the same name for different animals.\\nTl;dr: don’t assume a common understanding across hiring managers, recruiters, and practitioners. Look instead for specifics of tools, techniques, methodologies, and outputs. That being said, this one falls in the “plausible” category, because it may actually be true in some circumstances, while false in others.\\nPLAUSIBLE\\n\\nvia GIPHY\\n\\xa0\\nMyth #4: Data Science curricula are well-defined and consistent.\\nWe recommend checking this one out for yourself! A quick google search for bootcamps, master’s degree programs, and online courses will reveal that different organizations teach different things. There is no commonly accepted framework for teaching data science! Some focus more on the engineering, others focus more on machine learning, some think deep learning is foundational, and some prefer to use R. \\nOur curriculum was built through employer interviews, practitioner interviews, market research, and company partnerships. But we’re based in San Antonio! A bootcamp in New York might follow the same process and end up with a different syllabus. Keep in mind, whatever your learning path, that there will be gaps in your learning. The most important thing is to recognize those gaps.\\nBUSTED\\n\\nvia GIPHY\\n\\xa0\\nMyth #5: If I want to be a data scientist, I just need to learn Python or R.\\nThis one is common and dangerous! Just like statistics, programming languages like Python and R are tools. They’re just pieces of a larger puzzle! Knowing Python without understanding the data science pipeline is like knowing how to build a floor without having a floor plan. Of course, these are valuable technical skills that give you a leg up, but they’re second in importance to asking the right questions, knowing what tools to use when, and communicating your findings.\\nBUSTED\\n\\nvia GIPHY\\nStill have questions? Reach out to us at (210) 802-7289 or DataScience@codeup.com! Want to learn more about Data Science? Check out our recent blog posts at codeup.com/blog. And of course, if data science gets you excited, get started with us today at codeup.com/apply!\\n\\n\\n\\n\\n \\n\\n\\n\\n\\n\\n \\n\\n \\n\\n \\n\\n\\n \\n\\n \\n\\nJoin Us_ \\n\\nWe\\'re excited to launch our new Codeup newsletter, which highlights some interesting blog posts, things in the know, and upcoming events. We promise to keep things interesting and engaging - twice a month. \\n\\nGeneral_ \\n\\nStudents_ \\n\\nInfo_ \\n\\nLegal_ \\n\\n \\n\\n600 Navarro St. #350, San Antonio, Texas \\n\\n \\n\\n \\n\\n \\n\\n|   info@codeup.com \\n\\n   |   210 - 802 - 7289   \\n\\n \\n\\nComplaint Policy \\n\\nPrivacy Center\\n\\n\\nApply Now \\n\\nBlog \\n\\nWhy Codeup \\n\\nFAQ \\n\\nContact \\n\\nOur Programs \\n\\nFinancials \\n\\nWeb Development \\n\\nData Science \\n\\nHome \\n\\nAbout Codeup \\n\\nEmployers \\n\\nAlumni \\n\\nWe promise to keep things interesting and engaging - twice a month. \\n\\nCopyright All Rights Reserved © 2019 Codeup | Website Designed by Tribu Digital Marketing \\n\\n\\n \\nvar htmlDiv = document.getElementById(\"rs-plugin-settings-inline-css\"); var htmlDivCss=\"\";\\r\\n\\t\\t\\t\\tif(htmlDiv) {\\r\\n\\t\\t\\t\\t\\thtmlDiv.innerHTML = htmlDiv.innerHTML + htmlDivCss;\\r\\n\\t\\t\\t\\t}else{\\r\\n\\t\\t\\t\\t\\tvar htmlDiv = document.createElement(\"div\");\\r\\n\\t\\t\\t\\t\\thtmlDiv.innerHTML = \"<style>\" + htmlDivCss + \"</style>\";\\r\\n\\t\\t\\t\\t\\tdocument.getElementsByTagName(\"head\")[0].appendChild(htmlDiv.childNodes[0]);\\r\\n\\t\\t\\t\\t}\\r\\n\\t\\t\\t\\n\\r\\nif (setREVStartSize!==undefined) setREVStartSize(\\r\\n\\t{c: \\'#rev_slider_1_1\\', responsiveLevels: [1240,1024,778,480], gridwidth: [1240,1024,778,480], gridheight: [575,500,400,720], sliderLayout: \\'fullwidth\\'});\\r\\n\\t\\t\\t\\r\\nvar revapi1,\\r\\n\\ttpj;\\t\\r\\n(function() {\\t\\t\\t\\r\\n\\tif (!/loaded|interactive|complete/.test(document.readyState)) document.addEventListener(\"DOMContentLoaded\",onLoad); else onLoad();\\t\\r\\n\\tfunction onLoad() {\\t\\t\\t\\t\\r\\n\\t\\tif (tpj===undefined) { tpj = jQuery; if(\"off\" == \"on\") tpj.noConflict();}\\r\\n\\tif(tpj(\"#rev_slider_1_1\").revolution == undefined){\\n\\t\\trevslider_showDoubleJqueryError(\"#rev_slider_1_1\");\\n\\t}else{\\n\\t\\trevapi1 = tpj(\"#rev_slider_1_1\").show().revolution({\\n\\t\\t\\tsliderType:\"hero\",\\n\\t\\t\\tjsFileLocation:\"//codeup.com/wp-content/plugins/revslider/public/assets/js/\",\\n\\t\\t\\tsliderLayout:\"fullwidth\",\\n\\t\\t\\tdottedOverlay:\"none\",\\n\\t\\t\\tdelay:9000,\\n\\t\\t\\tresponsiveLevels:[1240,1024,778,480],\\n\\t\\t\\tvisibilityLevels:[1240,1024,778,480],\\n\\t\\t\\tgridwidth:[1240,1024,778,480],\\n\\t\\t\\tgridheight:[575,500,400,720],\\n\\t\\t\\tlazyType:\"none\",\\n\\t\\t\\tshadow:0,\\n\\t\\t\\tspinner:\"spinner0\",\\n\\t\\t\\tautoHeight:\"off\",\\n\\t\\t\\tdisableProgressBar:\"on\",\\n\\t\\t\\thideThumbsOnMobile:\"off\",\\n\\t\\t\\thideSliderAtLimit:0,\\n\\t\\t\\thideCaptionAtLimit:0,\\n\\t\\t\\thideAllCaptionAtLilmit:0,\\n\\t\\t\\tdebugMode:false,\\n\\t\\t\\tfallbacks: {\\n\\t\\t\\t\\tsimplifyAll:\"off\",\\n\\t\\t\\t\\tdisableFocusListener:false,\\n\\t\\t\\t}\\n\\t\\t});\\n\\t}; /* END OF revapi call */\\n\\t\\n }; /* END OF ON LOAD FUNCTION */\\r\\n}()); /* END OF WRAPPING FUNCTION */', 'url': 'https://codeup.com/data-science-myths/'}, {'title': 'data-science-vs-data-analytics-whats-the-difference', 'contents': 'By Dimitri Antoniou\\nA week ago, Codeup launched our immersive Data Science career accelerator! With our first class kicking off in February and only 25 seats available, we’ve been answering a lot of questions from prospective students. One in particular has come up so many times we decided to dedicate a blog post to it. What is the difference between data science and data analytics?\\nFirst, let’s define some of our terms! Take a look at this blog to understand what Data Science is. In short, it is a method of turning raw data into action, leading to a desired outcome. Big Data refers to data sets that are large and complex, usually exceeding the capacity of computers and normal processing power to deal with. Machine Learning is the process of ‘learning’ underlying patterns of data in order to automate the extraction of intelligence from that data.\\n\\nNow, let’s look at the data pipeline that data scientists work through to reach the actionable insights and outcomes we mentioned:\\n\\nWe start by collecting data, which may come from social media channels, network logs, financials, employee records, or more.\\nWe then process that data into usable information stored in databases or streamed.\\nNext, we look back on the history of that data to summarize, describe, and explain, turning the data into meaningful knowledge. Here we’re primarily using mathematics, statistics, and visualization methods.\\nNow we convert that knowledge into intelligence, seeking to predict future events so that we can make decisions in the present. This is where practitioners will introduce mathematical/statistical modeling through machine learning to their data.\\nFinally, we enable action by building automations, running tests, building visualizations, monitoring new data, etc.\\n\\nData professionals work at different stages of the spectrum to move data through the pipeline. On the left, Big Data Engineers specialize in collecting, storing, and processing data, getting it from Data to Information. In the middle, analysts work to understand and convert that information to knowledge. Lastly, a Machine Learning Engineer utilizes machine learning algorithms to turn intelligence into action by building automations, visualizations, recommendations, and predictions.\\nData Scientists span multiple stages of this pipeline, from information to action. They will spend about 70% of their time wrangling data in the information stage. They will conduct statistical analysis to derive knowledge. Lastly, they predict future events and build automations using machine learning.\\nFor those technical folk out there, data science is to data engineering or machine learning engineering as full-stack development is to front-end or back-end development. For the non-technical folk, data science is the umbrella term that houses data analytics, machine learning, and other data professions.\\nSo what’s the biggest difference between a data analyst and a data scientist? Data scientists utilize computer programming and machine learning in addition to mathematics and statistics. \\nStill have questions? Reach out to us at (210) 802-7289 or DataScience@codeup.com! Wondering which of Codeup’s programs is right for you? We’ve got you covered. And of course, if data science gets you excited, get started with us today at codeup.com/apply!', 'url': 'https://codeup.com/data-science-vs-data-analytics-whats-the-difference/'}, {'title': '10-tips-to-crush-it-at-the-sa-tech-job-fair', 'contents': '10 Tips to Crush It at the SA Tech Job Fair\\nSA Tech Job Fair\\nThe third bi-annual San Antonio Tech Job Fair is just around the corner. Over 25 companies will be at The Jack Guenther Pavilion\\xa0on April 10th, and they are hungry for new tech team members!\\nAt the job fair, companies want to quickly source a list of new talent leads. AKA they need to find qualified employees they can begin interviewing for jobs. Recruiters will represent their organization at tables with informational handouts and company swag. Your goal at a job fair is to set yourself apart from other candidates and ensure your name makes it to the top of those lead lists.\\nThink of your interaction with the company as a mini screening interview. The company rep will subtly evaluate basic qualities like your professionalism, communication and interpersonal skills, work experience, and interest level in the organization. Job fairs are also an opportunity for you to gain information about companies that may not be easily accessible online. \\xa0\\nAt Codeup, we’re passionate about bridging the gap between talent and demand, so we’ve outlined 10 tips to ensure you bring your A-game and leave a lasting impression!\\n10 Tips for Totally Crushing it at the SA Tech Job Fair\\n\\nUse keywords to describe your skills, but don’t go overboard. You’ll probably be talking to a recruiter or talent acquisition specialist. As a technical candidate, recognize these individuals usually aren’t developers or network administrators. They know terms like “JavaScript” and “Apache,” but haven’t written a line of code or spun up a server, so don’t get too caught up in industry jargon.\\nResearch the companies ahead of time. Review the list of attending companies and make sure you know what the company does and whether or not they hire people in your desired role. Look up recent news on the company and mention it during your conversation.\\nDefine your own goals for the job fair. Are you searching for a specific type of role or company culture? What matters most in your job search? Are there companies you want to prioritize? \\xa0Develop a game plan and be intentional with your time.\\nPrepare a stellar résumé. Bring about 20 copies of your résumé to the event, printed on nice paper. We won’t cover resume writing in this post, but there are a plethora of online resources you can consult. For job fairs, don’t worry about cover letters.\\nPolish your online profiles. If recruiters have a copy of your resume, you can be sure they will stalk you online soon. Make sure your online presence is professional and appropriate. A good place to start is by Googling yourself. Update your LinkedIn, and clean up any social media profiles.\\nCraft a 30-60 second elevator pitch. You may only have a few minutes with an employer. What will you say if they ask, “Tell me about yourself?” Consider structuring your pitch like this: Who you are + What you do + What your goals are + Why that matters to the company.\\nDon’t show up in a t-shirt, but trade in your suit for something more chill. Always keep it professional, but remember: tech is typically more casual than other industries. You’ll likely feel out of place if you look like you belong on Wall St., so refer to this guide on dressing for tech interviews.\\nDon’t forget the basics. Start and end each conversation with a firm handshake. Make eye contact while conversing. Smile! Thank the recruiter before you move on to the next table.\\nAsk educated questions. Don’t waste valuable face time with recruiters by asking questions like, “What does [Insert Company here] do?” They hate that question! Instead, try some of these:\\n\\nWhat are the top 3-5 examples of knowledge, skills, and abilities you look for in candidates?\\nWhat’s the best advice you have for someone who wants to work here?\\nWhat is your interview process like?\\nAre you hiring for any roles not currently listed on your websites?\\n\\n\\nFollow up. Collect business cards from each table. The next day, send a short note expressing your interest in the company’s opportunities and thanking the recruiter for his or her time.\\n\\nRSVP for the SA Tech Job Fair taking place at the Jack Guenther Pavilion – September 18th starting at 4 pm.', 'url': 'https://codeup.com/10-tips-to-crush-it-at-the-sa-tech-job-fair/'}, {'title': 'competitor-bootcamps-are-closing-is-the-model-in-danger', 'contents': 'Competitor Bootcamps Are Closing. Is the Model in Danger?\\n\\xa0\\n\\nIs the programming bootcamp model in danger?\\nIn recent news, DevBootcamp and The Iron Yard announced that they are closing their doors. This is big news. DevBootcamp was the first programming bootcamp model and The Iron Yard is a national player with 15 campuses across the U.S. In both cases, the companies cited an unsustainable business model. Does that mean the boot-camp model is dead?\\n\\ntl;dr “Nope!”\\nBootcamps exist because traditional education models have failed to provide students job-ready skills for the 21st century. Students demand better employment options from their education. Employers demand skilled and job ready candidates. Big Education’s failure to meet those needs through traditional methods created the fertile ground for the new business model of the programming bootcamp.\\nEducation giant Kaplan and Apollo Education Group (owner of University of Phoenix) bought their way into this new educational model when they purchased The Iron Yard and DevBootcamp. They purchased their competition with the intent to scale up the model. Unfortunately, Big Education is too habituated to coming up short for students. They bought the upstarts that challenged them, tried making changes to run those bootcamps in the “Big Education” way, and, sadly, they’ve closed the doors when they realized that scaling education is more challenging when student outcomes truly matter.\\nThe bootcamp model is still new and there will be plenty consolidation, competition, and changes in the future. This model is based on actually being adaptive, innovative, and sustainable. And there’s always room for innovation.\\n\\n\\nWhat we’ve learned at Codeup…\\n\\n\\nEducation is challenging to scale.\\nPrioritizing quality over growth pays off.\\n\\nWhat we’re doing at Codeup…\\n\\nHigher standards in our application process are leading to better student outcomes.\\nOur reputation and commitment to quality is opening new doors to previously uninterested/unreachable employers.\\nIn the beginning, the majority of Codeup graduates went to work with startups and small businesses. We’re now seeing a larger amount of our graduates place at medium to large sized businesses.\\nDemand is growing and employers are learning that the results are in the graduates.\\nCodeup’s model is sustainable, inclusive, and works.\\n\\nCall or contact us today to see how Codeup’s commitment to quality and approach to being a career accelerator can make a profound difference in your life.', 'url': 'https://codeup.com/competitor-bootcamps-are-closing-is-the-model-in-danger/'}]\n"
     ]
    }
   ],
   "source": [
    "articles = acquisition.get_blog_articles_save()\n",
    "print(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoor’s #1 best job in america.\n",
      "data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. we’ve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\n",
      "our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing web dev program. we’re focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\n",
      "applications are now open for codeup’s first data science cohort, which will start class on february 4, 2019. hurry – there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\n",
      "if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n"
     ]
    }
   ],
   "source": [
    "article = articles[0]['contents'].lower()\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Define a function named basic_clean. It should take in a string and apply some basic text cleaning to it:\n",
    "    * lowercase everything\n",
    "    * normalize unicode characters\n",
    "    * replace anything that is not a letter, number, whitespace or a single quote"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def basic_clean(str):\n",
    "    normalized = unicodedata.normalize('NFKD', str.lower())\\\n",
    "    .encode('ascii', 'ignore')\\\n",
    "    .decode('utf-8', 'ignore')\n",
    "\n",
    "    return normalized\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in glassdoors #1 best job in america.\n",
      "data science is a method of providing actionable intelligence from data. the data revolution has hit san antonio, resulting in an explosion in data scientist positions across companies like usaa, accenture, booz allen hamilton, and heb. weve even seen utsa invest $70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\n",
      "our program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\n",
      "we focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee  just like our existing web dev program. were focusing on data science with python, sql, and ml, covered in 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning  regression; 6) supervised machine learning  classification; 7) unsupervised machine learning  clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\n",
      "applications are now open for codeups first data science cohort, which will start class on february 4, 2019. hurry  there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\n",
      "if you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!\n"
     ]
    }
   ],
   "source": [
    "print(basic_clean(article))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Define a function named tokenize. It should take in a string and tokenize all the words in the string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(str):\n",
    "    tokenizer = nltk.tokenize.ToktokTokenizer()\n",
    "    return tokenizer.tokenize(str, return_str=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rumors are true ! the time has arrived. codeup has officially opened applications to our new data science career accelerator , with only 25 seats available ! this immersive program is one of a kind in san antonio , and will help you land a job in glassdoor ’ s #1 best job in america.\\ndata science is a method of providing actionable intelligence from data. the data revolution has hit san antonio , resulting in an explosion in data scientist positions across companies like usaa , accenture , booz allen hamilton , and heb. we ’ ve even seen utsa invest $ 70 m for a cybersecurity center and school of data science. we built a program to specifically meet the growing demands of this industry.\\nour program will be 18 weeks long , full-time , hands-on , and project-based. our curriculum development and instruction is led by senior data scientist , maggie giust , who has worked at heb , capital group , and rackspace , along with input from dozens of practitioners and hiring partners. students will work with real data sets , realistic problems , and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing , interviewing , and continuing education to prepare for a smooth transition to the workforce.\\nwe focus on applied data science for immediate impact and roi in a business , which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing web dev program. we ’ re focusing on data science with python , sql , and ml , covered in 14 modules : 1 ) fundamentals ; 2 ) applied statistics ; 3 ) sql ; 4 ) python ; 5 ) supervised machine learning – regression ; 6 ) supervised machine learning – classification ; 7 ) unsupervised machine learning – clustering ; 8 ) time series analysis ; 9 ) anomaly detection ; 10 ) natural language processing ; 11 ) distributed machine learning ; 12 ) advanced topics ( deep learning , nosql , cloud deployment , etc. ) ; 13 ) storytelling with data ; and 14 ) domain expertise development.\\napplications are now open for codeup ’ s first data science cohort , which will start class on february 4 , 2019. hurry – there are only 25 seats available ! to further our mission of cultivating inclusive growth , scholarships will be available to women , minorities , lgbtqia+ individuals , veterans , first responders , and people relocating to san antonio.\\nif you want to learn about joining our program or hiring our graduates , email datascience@codeup.com !'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Define a function named stem. It should accept some text and return the text after applying stemming to all the words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stem(str):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    stems = [ps.stem(word) for word in str.split()]\n",
    "    return ' '.join(stems)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have the best time, love you!'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stem('having the best time, love you!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Define a function named lemmatize. It should accept some text and return the text after applying lemmatization to each word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(str):\n",
    "    wnl = nltk.stem.WordNetLemmatizer()\n",
    "    lemmas = [wnl.lemmatize(word) for word in str.split()]\n",
    "    article_lemmatized = ' '.join(lemmas)\n",
    "    return article_lemmatized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'having the best time, love you!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize('having the best time, love you!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopword_list = stopwords.words('english')\n",
    "stopword_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. Define a function named remove_stopwords. It should accept some text and return the text after removing all the stopwords. ",
    "This function should define two optional parameters, extra_words and exclude_words. These parameters should define any additional stop words to include, and any words that we don't want to remove. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# extra_words = ['woop', 'like', 'kinda']\n",
    "# exclude_words = ['he', 'him', 'himself', 'his']\n",
    "# stopword_list2 = stopwords.words('english')\n",
    "\n",
    "# for word1 in extra_words:\n",
    "#     stopword_list2.append(word1)\n",
    "# print(stopword_list2)\n",
    "\n",
    "# for word2 in exclude_words:\n",
    "#     stopword_list2.remove(word2)\n",
    "# print(stopword_list2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(str, extra_words = None, exclude_words = None):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    words = str.split()\n",
    "    \n",
    "    if extra_words != None:\n",
    "        for element in extra_words:\n",
    "            stopword_list.append(element)\n",
    "            print('Added this element to the stopword_list: ', element)\n",
    "    if exclude_words != None:\n",
    "        for element in exclude_words:\n",
    "            if element in stopword_list:\n",
    "                stopword_list.remove(element)\n",
    "                print('Removed this element to the stopword_list: ', element)\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "    filtered_words = [w for w in words if w not in stopword_list]\n",
    "    article_without_stopwords = ' '.join(filtered_words)\n",
    "    return article_without_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the rumors are true! the time has arrived. codeup has officially opened applications to our new data science career accelerator, with only 25 seats available! this immersive program is one of a kind in san antonio, and will help you land a job in\\xa0glassdoor’s #1 best job in america.\\ndata science is a method of providing actionable intelligence from data.\\xa0the data revolution has hit san antonio,\\xa0resulting in an explosion in data scientist positions\\xa0across companies like usaa, accenture, booz allen hamilton, and heb. we’ve even seen\\xa0utsa invest $70 m for a cybersecurity center and school of data science.\\xa0we built a program to specifically meet the growing demands of this industry.\\nour program will be 18 weeks long, full-time, hands-on, and project-based. our curriculum development and instruction is led by senior data scientist, maggie giust, who has worked at heb, capital group, and rackspace, along with input from dozens of practitioners and hiring partners. students will work with real data sets, realistic problems, and the entire data science pipeline from collection to deployment. they will receive professional development training in resume writing, interviewing, and continuing education to prepare for a smooth transition to the workforce.\\nwe focus on applied data science for immediate impact and roi in a business, which is how we can back it all up with a 6 month tuition refund guarantee – just like our existing web dev program. we’re focusing on data science with python, sql, and ml, covered in\\xa014 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling with data; and 14) domain expertise development.\\napplications are now open\\xa0for codeup’s first data science cohort, which will start class on february 4, 2019. hurry – there are only 25 seats available! to further our mission of cultivating inclusive growth, scholarships will be available to women, minorities, lgbtqia+ individuals, veterans, first responders, and people relocating to san antonio.\\nif you want to learn about joining our program or hiring our graduates, email datascience@codeup.com!'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rumors true! time arrived. codeup officially opened applications new data science career accelerator, 25 seats available! immersive program one kind san antonio, help land job glassdoor’s #1 best job america. data science method providing actionable intelligence data. data revolution hit san antonio, resulting explosion data scientist positions across companies like usaa, accenture, booz allen hamilton, heb. we’ve even seen utsa invest $70 cybersecurity center school data science. built program specifically meet growing demands industry. program 18 weeks long, full-time, hands-on, project-based. curriculum development instruction led senior data scientist, maggie giust, worked heb, capital group, rackspace, along input dozens practitioners hiring partners. students work real data sets, realistic problems, entire data science pipeline collection deployment. receive professional development training resume writing, interviewing, continuing education prepare smooth transition workforce. focus applied data science immediate impact roi business, back 6 month tuition refund guarantee – like existing web dev program. we’re focusing data science python, sql, ml, covered 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling data; 14) domain expertise development. applications open codeup’s first data science cohort, start class february 4, 2019. hurry – 25 seats available! mission cultivating inclusive growth, scholarships available women, minorities, lgbtqia+ individuals, veterans, first responders, people relocating san antonio. want learn joining program hiring graduates, email datascience@codeup.com!'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added this element to the stopword_list:  data\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rumors true! time arrived. codeup officially opened applications new science career accelerator, 25 seats available! immersive program one kind san antonio, help land job glassdoor’s #1 best job america. science method providing actionable intelligence data. revolution hit san antonio, resulting explosion scientist positions across companies like usaa, accenture, booz allen hamilton, heb. we’ve even seen utsa invest $70 cybersecurity center school science. built program specifically meet growing demands industry. program 18 weeks long, full-time, hands-on, project-based. curriculum development instruction led senior scientist, maggie giust, worked heb, capital group, rackspace, along input dozens practitioners hiring partners. students work real sets, realistic problems, entire science pipeline collection deployment. receive professional development training resume writing, interviewing, continuing education prepare smooth transition workforce. focus applied science immediate impact roi business, back 6 month tuition refund guarantee – like existing web dev program. we’re focusing science python, sql, ml, covered 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling data; 14) domain expertise development. applications open codeup’s first science cohort, start class february 4, 2019. hurry – 25 seats available! mission cultivating inclusive growth, scholarships available women, minorities, lgbtqia+ individuals, veterans, first responders, people relocating san antonio. want learn joining program hiring graduates, email datascience@codeup.com!'"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(article, extra_words = ['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added this element to the stopword_list:  woop\n",
      "Added this element to the stopword_list:  like\n",
      "Added this element to the stopword_list:  kinda\n",
      "Added this element to the stopword_list:  glassdoor\n",
      "Removed this element to the stopword_list:  he\n",
      "Removed this element to the stopword_list:  him\n",
      "Removed this element to the stopword_list:  himself\n",
      "Removed this element to the stopword_list:  his\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'rumors true! time arrived. codeup officially opened applications new data science career accelerator, 25 seats available! immersive program one kind san antonio, help land job glassdoor’s #1 best job america. data science method providing actionable intelligence data. data revolution hit san antonio, resulting explosion data scientist positions across companies usaa, accenture, booz allen hamilton, heb. we’ve even seen utsa invest $70 cybersecurity center school data science. built program specifically meet growing demands industry. program 18 weeks long, full-time, hands-on, project-based. curriculum development instruction led senior data scientist, maggie giust, worked heb, capital group, rackspace, along input dozens practitioners hiring partners. students work real data sets, realistic problems, entire data science pipeline collection deployment. receive professional development training resume writing, interviewing, continuing education prepare smooth transition workforce. focus applied data science immediate impact roi business, back 6 month tuition refund guarantee – existing web dev program. we’re focusing data science python, sql, ml, covered 14 modules: 1) fundamentals; 2) applied statistics; 3) sql; 4) python; 5) supervised machine learning – regression; 6) supervised machine learning – classification; 7) unsupervised machine learning – clustering; 8) time series analysis; 9) anomaly detection; 10) natural language processing; 11) distributed machine learning; 12) advanced topics (deep learning, nosql, cloud deployment, etc.); 13) storytelling data; 14) domain expertise development. applications open codeup’s first data science cohort, start class february 4, 2019. hurry – 25 seats available! mission cultivating inclusive growth, scholarships available women, minorities, lgbtqia+ individuals, veterans, first responders, people relocating san antonio. want learn joining program hiring graduates, email datascience@codeup.com!'"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remove_stopwords(article, extra_words = ['woop', 'like', 'kinda','glassdoor'], exclude_words=['he', 'him', 'himself', 'his'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def how_many_stopwords(str):\n",
    "    stopword_list = stopwords.words('english')\n",
    "    words = str.split()\n",
    "    stop_words = [w for w in words if w in stopword_list]\n",
    "    print('Removed {} stopwords'.format(len(words) - len(stop_words)))\n",
    "    print('...from {} total words'.format(len(words)))\n",
    "    return stop_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 257 stopwords\n",
      "...from 378 total words\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['the',\n",
       " 'are',\n",
       " 'the',\n",
       " 'has',\n",
       " 'has',\n",
       " 'to',\n",
       " 'our',\n",
       " 'with',\n",
       " 'only',\n",
       " 'this',\n",
       " 'is',\n",
       " 'of',\n",
       " 'a',\n",
       " 'in',\n",
       " 'and',\n",
       " 'will',\n",
       " 'you',\n",
       " 'a',\n",
       " 'in',\n",
       " 'in',\n",
       " 'is',\n",
       " 'a',\n",
       " 'of',\n",
       " 'from',\n",
       " 'the',\n",
       " 'has',\n",
       " 'in',\n",
       " 'an',\n",
       " 'in',\n",
       " 'and',\n",
       " 'm',\n",
       " 'for',\n",
       " 'a',\n",
       " 'and',\n",
       " 'of',\n",
       " 'we',\n",
       " 'a',\n",
       " 'to',\n",
       " 'the',\n",
       " 'of',\n",
       " 'this',\n",
       " 'our',\n",
       " 'will',\n",
       " 'be',\n",
       " 'and',\n",
       " 'our',\n",
       " 'and',\n",
       " 'is',\n",
       " 'by',\n",
       " 'who',\n",
       " 'has',\n",
       " 'at',\n",
       " 'and',\n",
       " 'with',\n",
       " 'from',\n",
       " 'of',\n",
       " 'and',\n",
       " 'will',\n",
       " 'with',\n",
       " 'and',\n",
       " 'the',\n",
       " 'from',\n",
       " 'to',\n",
       " 'they',\n",
       " 'will',\n",
       " 'in',\n",
       " 'and',\n",
       " 'to',\n",
       " 'for',\n",
       " 'a',\n",
       " 'to',\n",
       " 'the',\n",
       " 'we',\n",
       " 'on',\n",
       " 'for',\n",
       " 'and',\n",
       " 'in',\n",
       " 'a',\n",
       " 'which',\n",
       " 'is',\n",
       " 'how',\n",
       " 'we',\n",
       " 'can',\n",
       " 'it',\n",
       " 'all',\n",
       " 'up',\n",
       " 'with',\n",
       " 'a',\n",
       " 'just',\n",
       " 'our',\n",
       " 'on',\n",
       " 'with',\n",
       " 'and',\n",
       " 'in',\n",
       " 'with',\n",
       " 'and',\n",
       " 'are',\n",
       " 'now',\n",
       " 'for',\n",
       " 'which',\n",
       " 'will',\n",
       " 'on',\n",
       " 'there',\n",
       " 'are',\n",
       " 'only',\n",
       " 'to',\n",
       " 'further',\n",
       " 'our',\n",
       " 'of',\n",
       " 'will',\n",
       " 'be',\n",
       " 'to',\n",
       " 'and',\n",
       " 'to',\n",
       " 'if',\n",
       " 'you',\n",
       " 'to',\n",
       " 'about',\n",
       " 'our',\n",
       " 'or',\n",
       " 'our']"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "how_many_stopwords(article)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. Define a function named prep_article that takes in the dictionary representing an article and returns a dictionary that looks like this:\n",
    "{'title': 'the original title',\n",
    "'original': original,\n",
    "'stemmed': article_stemmed,\n",
    "'lemmatized': article_lemmatized,\n",
    "'clean': article_without_stopwords}\n",
    "\n",
    "#### Note that if the orignal dictionary has a title property, it should remain unchanged (same goes for the category property)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stem((articles[0]['contents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatize((articles[0]['contents']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_article(dictionary):\n",
    "    return {\n",
    "        'title': dictionary['title'],\n",
    "        'original': dictionary['contents'], \n",
    "        'stemmed': stem(articles[0]['contents']),\n",
    "        'lemmatized': lemmatize(dictionary['contents']),\n",
    "        'clean': remove_stopwords(stem(basic_clean(tokenize(articles[0]['contents']))))\n",
    "        \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_article(articles[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Define a function named prepare_article_data that takes in the list of articles dictionaries, applies the prep_article function to each one, and returns the transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_article_data(list):\n",
    "    return [prep_article(element) for element in list]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepare_article_data(articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
